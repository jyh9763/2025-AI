{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 스케일링: 정규화(Normalization)와 표준화(Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 스케일링은 데이터의 서로 다른 피처(Feature, 변수)들의 값의 범위를 일정한 수준으로 맞추는 작업입니다. 예를 들어, '나이' (0~100)와 '연봉' (0~1,000,000,000)처럼 값의 범위가 크게 차이 나는 피처들이 있을 때, 스케일링을 통해 이들의 영향력을 동등하게 만들어 줄 수 있습니다.\n",
    "\n",
    "### 왜 스케일링이 필요한가?\n",
    "\n",
    "1.  **공정한 평가**: 값의 범위가 큰 피처가 모델 학습에 더 큰 영향을 미치는 것을 방지합니다.\n",
    "2.  **성능 향상**: 특히 거리를 기반으로 하는 알고리즘(KNN, SVM 등)이나 경사 하강법을 사용하는 알고리즘(선형 회귀, 로지스틱 회귀, 신경망 등)에서 학습 속도와 성능을 향상시킬 수 있습니다.\n",
    "\n",
    "대표적인 스케일링 방법으로 **정규화(Normalization)**와 **표준화(Standardization)**가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# 예제 데이터프레임 생성\n",
    "data = {\n",
    "    'age': [25, 45, 32, 58, 22, 38],\n",
    "    'salary': [50000, 85000, 62000, 120000, 45000, 70000],\n",
    "    'height': [175, 160, 182, 168, 170, 178]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- 원본 데이터프레임 ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 정규화 (Normalization)\n",
    "\n",
    "정규화는 데이터의 모든 피처 값을 **0과 1 사이의 값**으로 변환하는 방법입니다. 가장 널리 알려진 방법은 **최소-최대 스케일링(Min-Max Scaling)**입니다.\n",
    "\n",
    "- **공식**: `X_scaled = (X - X_min) / (X_max - X_min)`\n",
    "- **특징**:\n",
    "  - 모든 데이터가 0과 1 사이의 범위에 위치하게 됩니다.\n",
    "  - 데이터의 분포를 유지하면서 스케일을 조정합니다.\n",
    "  - **이상치(Outlier)에 매우 민감합니다.** 최솟값이나 최댓값이 극단적이면 대부분의 데이터가 매우 좁은 범위에 몰릴 수 있습니다.\n",
    "- **사용 경우**: 데이터의 분포가 특정 범위를 따르지 않을 때, 또는 값의 범위를 명확하게 0과 1 사이로 제한하고 싶을 때 (예: 이미지 픽셀 값 처리) 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 정규화 (Min-Max Scaling)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "# 스케일러를 데이터에 학습(fit)시키고 변환(transform)\n",
    "df_minmax_scaled = scaler_minmax.fit_transform(df)\n",
    "\n",
    "# 결과는 NumPy 배열이므로 다시 데이터프레임으로 변환\n",
    "df_minmax_scaled = pd.DataFrame(df_minmax_scaled, columns=df.columns)\n",
    "\n",
    "print(\"--- 정규화 (Min-Max Scaling) 후 데이터프레임 ---\")\n",
    "print(df_minmax_scaled)\n",
    "\n",
    "print(\"\\n--- 정규화 후 통계 정보 ---\")\n",
    "print(df_minmax_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 표준화 (Standardization)\n",
    "\n",
    "표준화는 각 피처의 평균을 0, 표준편차를 1로 변환하는 방법입니다. 이를 **Z-점수 정규화(Z-score Normalization)**라고도 합니다.\n",
    "\n",
    "- **공식**: `X_scaled = (X - mean) / std_dev` (mean: 평균, std_dev: 표준편차)\n",
    "- **특징**:\n",
    "  - 변환된 데이터는 평균이 0, 표준편차가 1인 분포를 가집니다.\n",
    "  - 값의 범위가 특정 구간으로 제한되지 않습니다 (음수 값도 가질 수 있음).\n",
    "  - **정규화에 비해 이상치에 덜 민감하여** 일반적으로 더 널리 사용됩니다.\n",
    "- **사용 경우**: 데이터가 가우시안 분포(정규 분포)를 따를 때, 또는 이상치가 존재할 가능성이 있을 때 효과적입니다. 대부분의 머신러닝 알고리즘에서 좋은 성능을 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 표준화 (Standardization)\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# 스케일러를 데이터에 학습(fit)시키고 변환(transform)\n",
    "df_standard_scaled = scaler_standard.fit_transform(df)\n",
    "\n",
    "# 결과는 NumPy 배열이므로 다시 데이터프레임으로 변환\n",
    "df_standard_scaled = pd.DataFrame(df_standard_scaled, columns=df.columns)\n",
    "\n",
    "print(\"--- 표준화 (Standardization) 후 데이터프레임 ---\")\n",
    "print(df_standard_scaled)\n",
    "\n",
    "print(\"\\n--- 표준화 후 통계 정보 ---\")\n",
    "print(df_standard_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표준화 결과 확인\n",
    "표준화된 데이터의 평균은 0에 가깝고, 표준편차는 1에 가까운 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"표준화 후 평균:\")\n",
    "print(np.mean(df_standard_scaled, axis=0))\n",
    "\n",
    "print(\"\\n표준화 후 표준편차:\")\n",
    "print(np.std(df_standard_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정규화 vs 표준화: 언제 무엇을 쓸까?\n",
    "\n",
    "정답은 없지만, 일반적인 가이드라인은 다음과 같습니다.\n",
    "\n",
    "| 구분 | **정규화 (Min-Max Scaling)** | **표준화 (Standardization)** |\n",
    "| :--- | :--- | :--- |\n",
    "| **범위** | 0 ~ 1 | 제한 없음 |\n",
    "| **이상치 민감도** | 높음 | 낮음 |\n",
    "| **추천 알고리즘** | - 데이터 분포를 모를 때<br>- 신경망(Neural Networks)<br>- K-최근접 이웃(KNN) | - 데이터가 정규분포를 따를 때<br>- 선형 회귀, 로지스틱 회귀<br>- SVM, LDA | \n",
    "| **일반적인 선택** | 특정 범위가 필요할 때 | **일반적으로 우선 고려 (더 안정적)** |\n",
    "\n",
    "**결론적으로, 어떤 스케일링 기법이 더 좋은지는 데이터의 특성과 사용하려는 모델에 따라 달라집니다. 따라서 두 가지 방법을 모두 시도해보고 더 나은 성능을 보이는 것을 선택하는 것이 좋습니다.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}