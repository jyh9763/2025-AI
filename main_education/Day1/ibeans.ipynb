{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_dir = \"data/train/train\"\n",
    "val_dir = \"data/validation/validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 shape 분석\n",
    "- 32 : 이미지의 개수 (한 배치 안에 32장)\n",
    "- 224 : height (픽셀)\n",
    "- 224 : width (픽셀)\n",
    "- 3 : 채널 수(RGB)\n",
    "\n",
    "- (32,) : 각 이미지가 어떤 클래스에 속하는지 알려주는 정답 정보(=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1034 files belonging to 3 classes.\n",
      "Found 133 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 생성\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,              # 학습 데이터 디렉토리 경로\n",
    "    image_size=(224, 224),  # 이미지 크기\n",
    "    batch_size=32,          # 배치 사이즈(한번에 처리할 이미지 크기)\n",
    "    shuffle=True,           # 데이터 섞기\n",
    "    seed=0                  # 재현성을 위한 시드 설정\n",
    ")\n",
    "\n",
    "# 검증 데이터 생성\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    val_dir,                # 검증 데이터 디렉토리 경로\n",
    "    image_size=(224, 224),  # 이미지 크기\n",
    "    batch_size=32,          # 배치 사이즈(한번에 처리할 이미지 크기)\n",
    "    shuffle=True,           # 데이터 섞기\n",
    "    seed=0                  # 재현성을 위한 시드 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angular_leaf_spot', 'bean_rust', 'healthy']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 layer 구성\n",
    "model = Sequential([\n",
    "    Rescaling(1./255, input_shape=(224, 224, 3)),   # 이미지 정규화\n",
    "    Conv2D(32, (3, 3), activation='relu'),          # 첫 번째 합성곱 층\n",
    "    MaxPooling2D((2, 2)),                           # 풀링 층\n",
    "    Conv2D(64, (3, 3), activation='relu'),          # 두 번째 합성곱 층\n",
    "    MaxPooling2D((2, 2)),                           # 풀링 층\n",
    "    Conv2D(128, (3, 3), activation='relu'),         # 세 번째 합성곱 층\n",
    "    MaxPooling2D((2, 2)),                           # 풀링 층\n",
    "    Flatten(),                                       # 평탄화 층\n",
    "    Dense(128, activation='relu'),                  # 완전 연결층\n",
    "    Dropout(0.5),                                   # 드롭아웃 층\n",
    "    Dense(len(class_names), activation='softmax')   # 출력층\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11075712  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,169,347\n",
      "Trainable params: 11,169,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3)\n",
    "model_checkpoint = ModelCheckpoint(\"ModelCheckpoint.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모델 저장 포맷 종류\n",
    "1) HDF5 포맷: 'model.h5'\n",
    "    - 가중치 + 구조 저장 가능\n",
    "2) SavedModel 포멧: 'model.keras'\n",
    "    - 2022: 가장 최신 모델 포맷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 18s 519ms/step - loss: 1.4279 - accuracy: 0.4130 - val_loss: 0.8678 - val_accuracy: 0.6466\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 15s 447ms/step - loss: 0.8521 - accuracy: 0.6238 - val_loss: 0.6913 - val_accuracy: 0.7368\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 15s 446ms/step - loss: 0.7579 - accuracy: 0.6663 - val_loss: 0.6571 - val_accuracy: 0.7293\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 15s 452ms/step - loss: 0.6962 - accuracy: 0.7108 - val_loss: 0.7429 - val_accuracy: 0.6466\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 15s 440ms/step - loss: 0.6268 - accuracy: 0.7408 - val_loss: 0.6075 - val_accuracy: 0.7218\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 16s 466ms/step - loss: 0.5749 - accuracy: 0.7795 - val_loss: 0.5578 - val_accuracy: 0.7820\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 16s 482ms/step - loss: 0.5171 - accuracy: 0.7872 - val_loss: 0.5507 - val_accuracy: 0.7744\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 16s 467ms/step - loss: 0.4709 - accuracy: 0.7950 - val_loss: 0.5943 - val_accuracy: 0.7293\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 0.4123 - accuracy: 0.8366 - val_loss: 0.6262 - val_accuracy: 0.7368\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 16s 466ms/step - loss: 0.3697 - accuracy: 0.8636 - val_loss: 0.5609 - val_accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "hist = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit의 핵심 3요소\n",
    "\n",
    "#### 1. epochs: 총 복습 횟수\n",
    "**epoch**는 전체 훈련 데이터셋을 몇 번 반복해서 학습할지를 결정함\n",
    "- 역할: 모델이 데이터를 충분히 학습할 기회를 제공한다.\n",
    "- 비유: 학생이 시험을 보기 위해 교과서를 몇 번 정독할지 정하는 것\n",
    "- 중요성:\n",
    "    - 너무 적으면(Underfitting): 모델이 데이터의 패턴을 충분히 학습하지 못함(과소적합)\n",
    "    - 너무 크면(Overfitting): 모델이 훈련 데이터에만 과도하게 최적화되어 새로운 데이터에 대한 성능이 떨어짐(과적합)\n",
    "\n",
    "#### 2. EarlyStopping: 학습 중단 신호\n",
    "**earlystopping**은 모델의 성능이 더 이상 개선되지 않으면 학습을 조기에 중단시킴\n",
    "- 역할: 과적합 방지, 불필요한 학습 시간 절약\n",
    "- 비유: 학생이 매주 모의고사를 공부했는데 점수가 오르지 않고 떨어지면 공부를 멈추는게 효율적이라고 판단하는 것\n",
    "- 주요 설정:\n",
    "    - monitor='val_loss': 이 값이 더 이상 감소하지 않으면 멈출 준비를 함\n",
    "    - patience=10: 점수가 오르지 않아도 10번의 epoch를 참고 기다려 줌\n",
    "    - restore_bset_weights=True **(매우 중요)**: 학습이 중단되었을 때, 지금까지 중 가장 좋았던 때의 가중치로 모델을 되돌려줌\n",
    "\n",
    "#### 3. ModelCheckpoint: 최고의 순간을 저장\n",
    "**ModelCheckpoint**는 학습 과정 동안 모델의 상태를 파일로 저장함\n",
    "- 역할: 학습 중 최고의 성능을 보인 모델을 저장하거나, 예기치 않게 학습이 중단될 경우를 대비해 중간 과정 저장\n",
    "- 비유: 학생이 공부하다가 컨디션이 좋고 문제가 잘 풀렸던 \"최고의 순간\"을 기록해두는 것\n",
    "- 주요 설정:\n",
    "    - filepath='best_model.keras': 모델을 저장할 파일 경로와 이름\n",
    "    - monitor='val_loss': 어떤 지표로 '최고'를 정할 건지 지정\n",
    "    - save_best_only=True: 성능이 더 좋아지면 그 모델을 덮어씌움\n",
    "    - save_weights_only=False: 모델의 구조, 가중치 등 전체 모델 저장 (True=가중치만 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.3\n",
      "Matplotlib version: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib as mp\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Matplotlib version:\", mp.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
