{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# 딥러닝의 내비게이션: 손실 함수 (Loss Function) 완벽 정복\n",
       "\n",
       "안녕하세요! 이 노트북에서는 딥러닝 모델을 똑똑하게 만드는 핵심 부품, **손실 함수**에 대해 알아보겠습니다. \n",
       "\n",
       "## 손실 함수의 역할: 모델의 성적표이자 내비게이션\n",
       "\n",
       "딥러닝 모델을 공부 잘하는 학생이라고 상상해 봅시다. 이 학생이 얼마나 잘하는지, 그리고 뭘 더 공부해야 할지 알려주는 것이 바로 **손실 함수**입니다. 손실 함수는 크게 세 가지 역할을 해요.\n",
       "\n",
       "1.  **예측 정확도 평가 (성적 매기기)**\n",
       "    - 모델이 내놓은 답안(`예측값`)과 실제 정답을 비교해서 **'얼마나 틀렸는지'** 점수를 매깁니다. 이 점수가 바로 **손실(Loss)** 값이에요. 점수가 낮을수록(0에 가까울수록) 모델이 똑똑하다는 뜻이죠.\n",
       "\n",
       "2.  **학습 방향 제시 (오답 노트)**\n",
       "    - 단순히 점수만 매기는 게 아니라, '어떤 방향으로 고쳐야 점수가 더 오를지' 알려줍니다. 모델은 이 피드백을 보고 자신의 내부 규칙(가중치)을 조금씩 수정하며 더 나은 답을 찾아갑니다.\n",
       "\n",
       "3.  **최적화 기준 제공 (학습 목표)**\n",
       "    - 딥러닝 학습의 최종 목표는 **'손실 값을 최소화하는 것'**입니다. 손실 함수는 이 명확한 목표를 제시함으로써 모델이 방황하지 않고 최고의 성능을 향해 나아가도록 합니다."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 예제에 필요한 라이브러리 가져오기\n",
       "import numpy as np"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "\n",
       "## 1. 회귀 모델 (Regression Model)의 손실 함수\n",
       "\n",
       "- **문제 유형**: 집값, 주가, 내일의 온도처럼 **연속적인 숫자**를 예측하는 문제.\n",
       "- **대표 손실 함수**: **평균 제곱 오차 (Mean Squared Error, MSE)**, **평균 절대 오차 (Mean Absolute Error, MAE)**"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 1-1. 평균 제곱 오차 (Mean Squared Error, MSE)\n",
       "\n",
       "가장 직관적이고 기본적인 손실 함수입니다. '오차(예측값과 정답의 차이)'를 제곱해서 평균을 낸 값이에요.\n",
       "\n",
       "**수식:**\n",
       "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
       "\n",
       "- $n$: 데이터의 개수\n",
       "- $y_i$: $i$번째 데이터의 실제 정답 값\n",
       "- $\\hat{y}_i$: 모델이 예측한 $i$번째 데이터의 값\n",
       "\n",
       "**핵심 아이디어**: 오차를 그냥 더하면 양수 오차와 음수 오차가 서로 상쇄될 수 있으니, **제곱해서 모두 양수로** 만들어줍니다. 또한, 오차를 제곱하기 때문에 **오차가 클수록 손실 값이 기하급수적으로 커져서** 모델이 큰 실수를 하지 않도록 강하게 제어하는 효과가 있습니다."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def mean_squared_error(y_true, y_pred):\n",
       "    \"\"\"평균 제곱 오차(MSE)를 계산합니다.\"\"\"\n",
       "    return np.mean((y_true - y_pred) ** 2)\n",
       "\n",
       "# 예제: 친구들의 키 예측하기\n",
       "y_true = np.array([165, 170, 178, 182])  # 실제 키 (정답)\n",
       "y_pred = np.array([167, 171, 175, 181])  # 모델이 예측한 키\n",
       "\n",
       "loss = mean_squared_error(y_true, y_pred)\n",
       "print(f\"친구들 키 예측의 MSE 손실: {loss:.2f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 1-2. 평균 절대 오차 (Mean Absolute Error, MAE)\n",
       "\n",
       "MSE와 비슷하지만, 오차를 제곱하는 대신 **오차의 절댓값**을 사용합니다.\n",
       "\n",
       "**수식:**\n",
       "$$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
       "\n",
       "- $n$: 데이터의 개수\n",
       "- $y_i$: $i$번째 데이터의 실제 정답 값\n",
       "- $\\hat{y}_i$: 모델이 예측한 $i$번째 데이터의 값\n",
       "\n",
       "**핵심 아이디어**: 오차의 크기 그대로를 손실에 반영합니다. MSE처럼 오차가 크다고 해서 손실이 기하급수적으로 커지지 않기 때문에, **이상치(outlier, 유난히 튀는 값)에 덜 민감**한 특징이 있습니다. 모든 오차를 동등하게 취급하고 싶을 때 유용합니다."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def mean_absolute_error(y_true, y_pred):\n",
       "    \"\"\"평균 절대 오차(MAE)를 계산합니다.\"\"\"\n",
       "    return np.mean(np.abs(y_true - y_pred))\n",
       "\n",
       "# 예제: 친구들의 키 예측하기 (이상치 포함)\n",
       "y_true_with_outlier = np.array([165, 170, 178, 182, 210])  # 마지막에 210cm라는 이상치 추가\n",
       "y_pred_for_outlier = np.array([167, 171, 175, 181, 185])  # 모델의 예측\n",
       "\n",
       "loss_mae = mean_absolute_error(y_true_with_outlier, y_pred_for_outlier)\n",
       "loss_mse = mean_squared_error(y_true_with_outlier, y_pred_for_outlier) # 같은 데이터로 MSE도 계산\n",
       "\n",
       "print(f\"이상치 포함 데이터의 MAE 손실: {loss_mae:.2f}\")\n",
       "print(f\"이상치 포함 데이터의 MSE 손실: {loss_mse:.2f}\")\n",
       "print(\"\\n=> 이상치(210cm) 때문에 MSE 손실이 MAE에 비해 훨씬 크게 증가한 것을 볼 수 있습니다.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "\n",
       "## 2. 이진 분류 (Binary Classification)의 손실 함수\n",
       "\n",
       "- **문제 유형**: 스팸 메일/정상 메일, 합격/불합격처럼 **둘 중 하나를 선택**하는 문제.\n",
       "- **대표 손실 함수**: **이진 교차 엔트로피 (Binary Cross-Entropy, BCE)**\n",
       "\n",
       "### 이진 교차 엔트로피 (BCE)\n",
       "\n",
       "모델이 예측한 '확률'을 가지고 손실을 계산합니다. 모델이 정답에 대해 얼마나 확신을 가지고 맞혔는지를 평가해요.\n",
       "\n",
       "**수식:**\n",
       "$$ \\text{BCE} = - \\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)] $$\n",
       "\n",
       "- $y_i$: 실제 정답 (0 또는 1)\n",
       "- $\\hat{y}_i$: 모델이 1일 것이라고 예측한 **확률** (예: 0.8은 80% 확률)\n",
       "\n",
       "**핵심 아이디어**: \n",
       "- **정답이 1일 때($y_i=1$)**: 모델이 1에 가까운 확률($\\hat{y}_i \\approx 1$)로 예측하면 $\\log(\\hat{y}_i)$는 0에 가까워져 손실이 작아집니다. 반면 0에 가까운 확률로 예측하면 손실이 무한대로 커집니다.\n",
       "- **정답이 0일 때($y_i=0$)**: 위와 반대로, 모델이 0에 가까운 확률($\\hat{y}_i \\approx 0$)로 예측해야 손실이 작아집니다.\n",
       "결론적으로, **정답을 높은 확률로 맞히면 손실이 작고, 낮은 확률로 맞히거나 틀리면 손실이 매우 커집니다.**"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def binary_cross_entropy(y_true, y_pred):\n",
       "    \"\"\"이진 교차 엔트로피(BCE)를 계산합니다.\"\"\"\n",
       "    # log(0)을 방지하기 위해 아주 작은 값(epsilon)을 더하거나 뺍니다.\n",
       "    epsilon = 1e-15\n",
       "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
       "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
       "\n",
       "# 예제: 고양이/강아지 사진 구분하기 (1: 고양이, 0: 강아지)\n",
       "y_true = np.array([1, 0, 1, 0]) # 실제 정답: [고양이, 강아지, 고양이, 강아지]\n",
       "\n",
       "# 모델 A: 잘 맞춤\n",
       "y_pred_A = np.array([0.9, 0.2, 0.8, 0.1]) # 고양이일 확률을 예측\n",
       "loss_A = binary_cross_entropy(y_true, y_pred_A)\n",
       "print(f\"모델 A (잘 맞춤)의 BCE 손실: {loss_A:.4f}\")\n",
       "\n",
       "# 모델 B: 잘 못 맞춤\n",
       "y_pred_B = np.array([0.3, 0.6, 0.4, 0.9]) # 고양이일 확률을 예측\n",
       "loss_B = binary_cross_entropy(y_true, y_pred_B)\n",
       "print(f\"모델 B (못 맞춤)의 BCE 손실: {loss_B:.4f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "\n",
       "## 3. 다중 클래스 분류 (Multi-class Classification)의 손실 함수\n",
       "\n",
       "- **문제 유형**: 손글씨 숫자(0~9) 맞히기, 이미지 종류(개/고양이/새) 맞히기처럼 **여러 선택지 중 단 하나**를 고르는 문제.\n",
       "- **대표 손실 함수**: **범주형 교차 엔트로피 (Categorical Cross-Entropy, CCE)**\n",
       "\n",
       "### 범주형 교차 엔트로피 (CCE)\n",
       "\n",
       "BCE를 여러 클래스 버전으로 확장한 것입니다. 모델이 모든 선택지에 대해 예측한 확률 분포와 실제 정답(하나만 1이고 나머지는 0)을 비교합니다.\n",
       "\n",
       "**수식:**\n",
       "$$ \\text{CCE} = - \\sum_{i=1}^{C} y_{i} \\log(\\hat{y}_{i}) $$\n",
       "\n",
       "- $C$: 전체 클래스(선택지)의 개수\n",
       "- $y_i$: $i$번째 클래스가 정답이면 1, 아니면 0 (이를 **원-핫 인코딩**이라 부릅니다)\n",
       "- $\\hat{y}_i$: 모델이 $i$번째 클래스일 것이라고 예측한 **확률**\n",
       "\n",
       "**핵심 아이디어**: 수식이 복잡해 보이지만, 실제 정답($y_i=1$)인 클래스는 하나뿐이므로 결국 **'정답 클래스에 대해 모델이 예측한 확률'에만 로그를 취해 손실을 계산**하는 것과 같습니다. 즉, 정답을 얼마나 높은 확률로 예측했는지를 평가합니다."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def categorical_cross_entropy(y_true, y_pred):\n",
       "    \"\"\"범주형 교차 엔트로피(CCE)를 계산합니다.\"\"\"\n",
       "    epsilon = 1e-15\n",
       "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
       "    # y_true가 원-핫 인코딩 되어 있으므로, 곱셈을 통해 정답 클래스의 예측 확률만 남깁니다.\n",
       "    return -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]\n",
       "\n",
       "# 예제: 가위바위보 이미지 분류 (0: 가위, 1: 바위, 2: 보)\n",
       "# 정답: [바위, 보, 가위]\n",
       "y_true = np.array([\n",
       "    [0, 1, 0],  # 바위\n",
       "    [0, 0, 1],  # 보\n",
       "    [1, 0, 0]   # 가위\n",
       "])\n",
       "\n",
       "# 모델 예측 (각 행은 [가위 확률, 바위 확률, 보 확률])\n",
       "y_pred = np.array([\n",
       "    [0.1, 0.8, 0.1], # 바위를 80% 확률로 잘 예측\n",
       "    [0.3, 0.3, 0.4], # 보를 40% 확률로 애매하게 예측\n",
       "    [0.2, 0.7, 0.1]  # 가위가 정답인데 바위를 70%로 잘못 예측\n",
       "])\n",
       "\n",
       "loss = categorical_cross_entropy(y_true, y_pred)\n",
       "print(f\"가위바위보 분류의 CCE 손실: {loss:.4f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "\n",
       "## 4. 다중 레이블 분류 (Multi-label Classification)의 손실 함수\n",
       "\n",
       "- **문제 유형**: 하나의 영화에 '액션', '코미디', 'SF' 등 **여러 개의 장르**를 동시에 태그하거나, 뉴스 기사에 여러 개의 카테고리를 붙이는 문제. 즉, **여러 선택지 중 여러 개를 고를 수 있는** 문제.\n",
       "- **대표 손실 함수**: **이진 교차 엔트로피 (Binary Cross-Entropy, BCE)**\n",
       "\n",
       "### 다중 레이블에서의 BCE 활용\n",
       "\n",
       "다중 '클래스' 분류와는 다르게, 각 레이블(선택지)이 서로 독립적입니다. 영화가 액션인 것과 코미디인 것은 별개의 문제이죠. 따라서 이 문제를 **'여러 개의 독립적인 이진 분류 문제'**로 생각할 수 있습니다.\n",
       "\n",
       "**핵심 아이디어**: '이 영화는 액션인가? (Y/N)', '이 영화는 코미디인가? (Y/N)', '이 영화는 SF인가? (Y/N)' 처럼 **각 레이블마다 독립적으로 BCE 손실을 계산한 뒤, 모두 평균**을 냅니다. 사용하는 수식은 이진 분류의 BCE와 완전히 동일합니다."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 다중 레이블 분류에는 이진 교차 엔트로피 함수를 그대로 사용합니다.\n",
       "\n",
       "# 예제: 영화 장르 태그하기 ([액션, 코미디, 로맨스])\n",
       "# 정답: [액션, 로맨스], [코미디], [액션, 코미디, 로맨스]\n",
       "y_true = np.array([\n",
       "    [1, 0, 1],\n",
       "    [0, 1, 0],\n",
       "    [1, 1, 1]\n",
       "])\n",
       "\n",
       "# 모델 예측 (각 장르에 대한 독립적인 확률)\n",
       "y_pred = np.array([\n",
       "    [0.9, 0.2, 0.8], # 액션, 로맨스일 확률을 높게 잘 예측\n",
       "    [0.1, 0.7, 0.3], # 코미디일 확률을 높게 잘 예측\n",
       "    [0.4, 0.3, 0.2]  # 전체적으로 잘못 예측\n",
       "])\n",
       "\n",
       "# 각 샘플, 각 레이블에 대해 BCE를 계산하고 전체 평균을 냅니다.\n",
       "loss = binary_cross_entropy(y_true, y_pred)\n",
       "print(f\"영화 장르 태그의 BCE 손실: {loss:.4f}\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   